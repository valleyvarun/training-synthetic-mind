<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training the Synthetic Mind</title>
  <link href="https://fonts.googleapis.com/css2?family=Fira+Code&display=swap" rel="stylesheet">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@700&family=Inter:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Fira+Code&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <div class="sticker">1st draft</div>
    Training the Synthetic Mind
    <div class="header-details">
      <div>Varun SA</div>
      <div>MS CDP</div>
    </div>
  </header>

  <div class="all-sections">

    <!-- Section 1 - title, research questions -->
  <div class="section">
  <div class="content">

    <div class="text-box">
      <div class="section-heading">
        1. Title:
      </div>
      <div class="text-content">
        Training the Synthetic Mind: The Future of Multimodal Datasets
      </div>

      <div class="section-heading">
        2. Research Questions:
      </div>
      <div class="section-heading">
        What questions does your project raise?
      </div>
      <div class="text-content">
        <ul>
  <li>Why do we need multimodal AI, and how will the datasets required to train it differ from those used today?</li>
  <li>How can complex digital assets—such as 3D models, simulation objects, videos, images, and materials—be intentionally sourced, structured, and standardized for AI training?</li>
  <li>Who will own the rights to these training datasets, and what systems can ensure proper attribution and fair compensation for contributors?</li>
  <li>What are the limitations of current web-scraped datasets, and how can collaborative, provenance-aware dataset creation practices lead to more equitable and effective
      </div>
    </div>

    <div class="media">
      bye
    </div>
  </div>
</div>


<!-- Section 2 -->
<div class="section">
  <div class="content">
    <!-- Media on the left this time -->
    <div class="media">
      bye
    </div>
    <div class="text-box">
      <div class="section-heading">
        2. Research Questions:
      </div>
      <div class="section-heading">
        What are you curious about?
      </div>
      <div class="text-content">
        <ul>
            <li>What multimodal AIs and datasets are currently being developed?</li>
            <li>How are these datasets being built, and who is contributing to them?</li>
        </ul>
      </div>
      <div class="section-heading">
        Does your work connect to societal discussions and debates taking place at the moment?
      </div>
      <div class="text-content">
        <ul>
        <li>Yes, there are increasing concerns around bias and racism in AI models—caused not only by lack of diversity in datasets but also by the inability of models to understand the world in a nuanced way.</li>
        <li>Widespread protest exists around data scraping from the internet without consent, especially from social media and creative platforms.</li>
        <li>NFTs are being explored as a mechanism for digital ownership, especially in creative and digital asset spaces.</li>
        </ul>
      </div>
    </div>
  </div>
</div>


<!-- Section 3 -->
<div class="section">
  <div class="content">
    <div class="text-box">
      <div class="section-heading">
        2. Research Questions:
      </div>

      <div class="section-heading">
        Does your work touch on policy proposals for the future of technology and its regulation?
      </div>
      <div class="text-content">
        <ul>
          <li>Yes, it raises the need for:
            <ul>
              <li>A system for training multimodal AI ethically and inclusively</li>
              <li>A system for digital asset ownership and attribution</li>
            </ul>
          </li>
        </ul>
      </div>

      <div class="section-heading">
        Does your research question a socio-technical problem?
      </div>
      <div class="text-content">
        <ul>
          <li>Yes. It investigates how to reduce bias in AI by improving contextual understanding through multimodal inputs.</li>
          <li>It also proposes a more equitable framework where individuals are compensated for their contributions to AI training datasets.</li>
          <li>It supports a more inclusive and open approach to dataset creation and use.</li>
        </ul>
      </div>
    </div>

    <div class="media">
      bye
    </div>
  </div>
</div>




<!-- Section 4 -->
<div class="section">
  <div class="content">
    <!-- Media on the left this time -->
    <div class="media">
      bye
    </div>
    <div class="text-box">
      <div class="section-heading">
        3. Keywords
      </div>
      <div class="text-content">
        Datasets, Multimodal, AI, NFT, Digital Provenance, Omniverse
      </div>

      <div class="section-heading">
        4. Intersecting Fields
      </div>
      <div class="text-content">
        Artificial Intelligence, Data Ethics, Simulation & Digital Twin Environments, Blockchain / NFTs / Digital Provenance
      </div>

      <div class="section-heading">
        5. Historical Lineage
      </div>
      <div class="section-heading">
        What historical lineage does your work emerge from?
      </div>
      <div class="text-content">
        <ul>
          <li>Originates from early dataset-based AI models like those used for object recognition and OCR (Optical Character Recognition).</li>
          <li>Builds upon unimodal and bimodal generative AIs like:
            <ul>
              <li>Text-only models (early ChatGPT, DeepSeek, etc.)</li>
              <li>Text-to-image models (Midjourney, DALL·E, Stable Diffusion)</li>
            </ul>
          </li>
          <li>Responds to recent criticism of large-scale dataset scraping without consent or compensation.</li>
          <li>Engages with the emerging conversation around digital rights, particularly through the growing use of NFTs for digital asset ownership.</li>
        </ul>
      </div>
    </div>
  </div>
</div>



<!-- Section 5 -->
<div class="section">
  <div class="content">
    <div class="text-box">
      <div class="section-heading">
        5. Historical Lineage
      </div>

      <div class="section-heading">
        What trajectory are you continuing?
      </div>
      <div class="text-content">
        <ul>
          <li>Moving beyond unimodal and bimodal AI systems toward multimodal intelligence, which integrates video, audio, text, 3D models, physics simulations, and more.</li>
          <li>Exploring how simulation-based and user-contributed digital assets (e.g. functioning models of buildings, vehicles, animals) can serve as structured training data.</li>
          <li>Advocating for a secure, tokenized system of digital asset ownership that uses NFTs for attribution, rights management, and monetized access.</li>
        </ul>
      </div>

      <div class="section-heading">
        Related Books:
      </div>
      <div class="text-content">
        <em>Who Owns the Future?</em> by Jaron Lanier, <em>Uberworked and Underpaid</em> by Trebor Scholz
      </div>

      <div class="section-heading">
        Articles/Projects:
      </div>
      <div class="text-content">
        Excavating AI, ImageNet Roulette
      </div>
    </div>

    <div class="media">
      bye
    </div>
  </div>
</div>


<!-- Section 6 -->
<div class="section">
  <div class="content">
    <div class="media">
      bye
    </div>
    <div class="text-box">
      <div class="section-heading">
        6. Your Community of Practice:
      </div>

      <div class="section-heading">
        Who else is working in this space?
      </div>
      <div class="text-content">
        <ul>
          <li>
            <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank">NVIDIA Omniverse</a> – a collaborative platform for real-time 3D content creation, simulation, digital twins, and synthetic data generation.
          </li>
          <li>
            <a href="https://oceanprotocol.com/" target="_blank">Ocean Protocol</a> – a decentralized infrastructure for secure and monetized data sharing.
          </li>
          <li>
            <a href="https://omniobject3d.github.io/" target="_blank">OmniObject3D</a> – a large-scale dataset of high-fidelity 3D object models for vision, simulation, and robotics training.
          </li>
          <li>
            <a href="https://objaverse.allenai.org/" target="_blank">Objaverse</a> – a collection of 3D assets designed for training multimodal and embodied AI models.
          </li>
          <li>
            <a href="https://concept-fusion.github.io/" target="_blank">ConceptFusion</a> – pixel-aligned open-set 3D mapping for multimodal reasoning (text, image, geometry) :contentReference[oaicite:2]{index=2}
          </li>
          <li>
            A broader community of designers, developers, and researchers exploring AI ethics, data provenance, decentralized infrastructure, and digital rights.
          </li>
        </ul>
      </div>
    </div>
  </div>
</div>

<!-- Section 7 -->
<div class="section">
  <div class="content">
    <div class="text-box">
      <div class="section-heading">
        6. Your Community of Practice:
      </div>

      <div class="section-heading">
        How do you position yourself?
      </div>
      <div class="text-content">
        <ul>
          <li>As a designer-researcher focused on building intentional, high-quality datasets for training the next generation of multimodal AI systems.</li>
          <li>My work is rooted in the question of how datasets are created, owned, and shared, positioning me within broader conversations around AI ethics, digital provenance, and decentralized infrastructure.</li>
        </ul>
      </div>
    </div>
    <div class="media">
      bye
    </div>
  </div>
</div>







</div>


   <script src="script.js"></script>
</body>
</html>
